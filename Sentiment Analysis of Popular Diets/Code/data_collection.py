# -*- coding: utf-8 -*-
"""data_collection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_G7w0W7MjK9p9NQxMXytQcOnFhyu5dy9
"""

!pip install praw

import praw
import pandas as pd
from datetime import datetime, timedelta

reddit = praw.Reddit(
    client_id='50jdHiuALUKGJq0eQpYtgw',
    client_secret='m9fVtgEu0l5UWPijSxQqcxJx531byA',
    user_agent='REDDIT_COMMENTS'
)

"""BALANCED"""

from praw.models import MoreComments
post_id = '1cht83x'
num_comments = 100

post = reddit.submission(id=post_id)

comments = post.comments[:num_comments]

data = []

def getComments(comments):
    try:
        for comment in comments:
            if isinstance(comment,MoreComments):
                # This is a comment that has more comments inside it
                # We need to go through those sub comments
                getComments(comment.comments)
                continue
            if comment.author is None or comment.author.name == '[deleted]':
                # Skip deleted users or removed comments
                continue
            author = comment.author.name if comment.author else '[deleted]'
            text = comment.body
            date = comment.created_utc
            score = comment.score
            data.append([author, text, date, score, 'paleo'])
    except:
        print("")

getComments(comments)

# Create a pandas DataFrame from the data
df = pd.DataFrame(data, columns=['Author', 'Text', 'Date', 'Score', 'Keyword'])

# Write the DataFrame to a CSV file
df.to_csv('reddit_data_bpaleo.csv', index=False)

from praw.models import MoreComments
post_id = '1elx6lw'
num_comments = 85

post = reddit.submission(id=post_id)

comments = post.comments[:num_comments]

data = []

def getComments(comments):
    try:
        for comment in comments:
            if isinstance(comment,MoreComments):
                # This is a comment that has more comments inside it
                # We need to go through those sub comments
                getComments(comment.comments)
                continue
            if comment.author is None or comment.author.name == '[deleted]':
                # Skip deleted users or removed comments
                continue
            author = comment.author.name if comment.author else '[deleted]'
            text = comment.body
            date = comment.created_utc
            score = comment.score
            data.append([author, text, date, score,'vegan'])
    except:
        print("")

getComments(comments)

# Create a pandas DataFrame from the data
df1 = pd.DataFrame(data, columns=['Author', 'Text', 'Date', 'Score', 'Keyword'])

# Write the DataFrame to a CSV file
df1.to_csv('reddit_data_bvegan.csv', index=False)

from praw.models import MoreComments
post_id = '19f3g47'
num_comments = 85

post = reddit.submission(id=post_id)

comments = post.comments[:num_comments]

data = []

def getComments(comments):
    try:
        for comment in comments:
            if isinstance(comment,MoreComments):
                # This is a comment that has more comments inside it
                # We need to go through those sub comments
                getComments(comment.comments)
                continue
            if comment.author is None or comment.author.name == '[deleted]':
                # Skip deleted users or removed comments
                continue
            author = comment.author.name if comment.author else '[deleted]'
            text = comment.body
            date = comment.created_utc
            score = comment.score
            data.append([author, text, date, score,'keto'])
    except:
        print("")

getComments(comments)

# Create a pandas DataFrame from the data
df2 = pd.DataFrame(data, columns=['Author', 'Text', 'Date', 'Score', 'Keyword'])

# Write the DataFrame to a CSV file
df2.to_csv('reddit_data_bketo.csv', index=False)

import pandas as pd

# Assuming your six dataframes are named df1, df2, df3, df4, df5, and df6
balanced_df = pd.concat([df, df1, df2], ignore_index=True)
balanced_df.to_csv('reddit_data_b.csv', index=False)



"""KETO"""

from praw.models import MoreComments
post_id = '1ep2rnf'
num_comments = 70

post = reddit.submission(id=post_id)

comments = post.comments[:num_comments]

data = []

def getComments(comments):
    try:
        for comment in comments:
            if isinstance(comment,MoreComments):
                # This is a comment that has more comments inside it
                # We need to go through those sub comments
                getComments(comment.comments)
                continue
            if comment.author is None or comment.author.name == '[deleted]':
                # Skip deleted users or removed comments
                continue
            author = comment.author.name if comment.author else '[deleted]'
            text = comment.body
            date = comment.created_utc
            score = comment.score
            data.append([author, text, date, score,'keto'])
    except:
        print("")

getComments(comments)

# Create a pandas DataFrame from the data
df3 = pd.DataFrame(data, columns=['Author', 'Text', 'Date', 'Score', 'Keyword'])

# Write the DataFrame to a CSV file
df3.to_csv('reddit_data_keto1.csv', index=False)

from praw.models import MoreComments
post_id = '1efybfm'
num_comments = 85

post = reddit.submission(id=post_id)

comments = post.comments[:num_comments]

data = []

def getComments(comments):
    try:
        for comment in comments:
            if isinstance(comment,MoreComments):
                # This is a comment that has more comments inside it
                # We need to go through those sub comments
                getComments(comment.comments)
                continue
            if comment.author is None or comment.author.name == '[deleted]':
                # Skip deleted users or removed comments
                continue
            author = comment.author.name if comment.author else '[deleted]'
            text = comment.body
            date = comment.created_utc
            score = comment.score
            data.append([author, text, date, score,'keto'])
    except:
        print("")

getComments(comments)

# Create a pandas DataFrame from the data
df4 = pd.DataFrame(data, columns=['Author', 'Text', 'Date', 'Score', 'Keyword'])

# Write the DataFrame to a CSV file
df4.to_csv('reddit_data_keto2.csv', index=False)

df_keto = pd.concat([df3, df4], ignore_index=True)
df_keto.to_csv('reddit_data_keto.csv', index=False)

"""VEGAN

"""

from praw.models import MoreComments
post_id = '14neqaj'
num_comments = 100

post = reddit.submission(id=post_id)

comments = post.comments[:num_comments]

data = []

def getComments(comments):
    try:
        for comment in comments:
            if isinstance(comment,MoreComments):
                # This is a comment that has more comments inside it
                # We need to go through those sub comments
                getComments(comment.comments)
                continue
            if comment.author is None or comment.author.name == '[deleted]':
                # Skip deleted users or removed comments
                continue
            author = comment.author.name if comment.author else '[deleted]'
            text = comment.body
            date = comment.created_utc
            score = comment.score
            data.append([author, text, date, score,'vegan'])
    except:
        print("")

getComments(comments)

# Create a pandas DataFrame from the data
df5 = pd.DataFrame(data, columns=['Author', 'Text', 'Date', 'Score', 'Keyword'])

# Write the DataFrame to a CSV file
df5.to_csv('reddit_data_vegan1.csv', index=False)

from praw.models import MoreComments
post_id = '1gpwekp'
num_comments = 100

post = reddit.submission(id=post_id)

comments = post.comments[:num_comments]

data = []

def getComments(comments):
    try:
        for comment in comments:
            if isinstance(comment,MoreComments):
                # This is a comment that has more comments inside it
                # We need to go through those sub comments
                getComments(comment.comments)
                continue
            if comment.author is None or comment.author.name == '[deleted]':
                # Skip deleted users or removed comments
                continue
            author = comment.author.name if comment.author else '[deleted]'
            text = comment.body
            date = comment.created_utc
            score = comment.score
            data.append([author, text, date, score,'vegan'])
    except:
        print("")

getComments(comments)

# Create a pandas DataFrame from the data
df6 = pd.DataFrame(data, columns=['Author', 'Text', 'Date', 'Score', 'Keyword'])

# Write the DataFrame to a CSV file
df6.to_csv('reddit_data_vegan2.csv', index=False)

df_vegan = pd.concat([df5, df6], ignore_index=True)
df_vegan.to_csv('reddit_data_vegan.csv', index=False)

"""PALEO"""

from praw.models import MoreComments
post_id = '1dk2gde'
num_comments = 100

post = reddit.submission(id=post_id)

comments = post.comments[:num_comments]

data = []

def getComments(comments):
    try:
        for comment in comments:
            if isinstance(comment,MoreComments):
                # This is a comment that has more comments inside it
                # We need to go through those sub comments
                getComments(comment.comments)
                continue
            if comment.author is None or comment.author.name == '[deleted]':
                # Skip deleted users or removed comments
                continue
            author = comment.author.name if comment.author else '[deleted]'
            text = comment.body
            date = comment.created_utc
            score = comment.score
            data.append([author, text, date, score, 'paleo'])
    except:
        print("")

getComments(comments)

# Create a pandas DataFrame from the data
df9 = pd.DataFrame(data, columns=['Author', 'Text', 'Date', 'Score', 'Keyword'])

# Write the DataFrame to a CSV file
df9.to_csv('reddit_data_paleo1.csv', index=False)

from praw.models import MoreComments
post_id = '14ak6je'
num_comments = 100

post = reddit.submission(id=post_id)

comments = post.comments[:num_comments]

data = []

def getComments(comments):
    try:
        for comment in comments:
            if isinstance(comment,MoreComments):
                # This is a comment that has more comments inside it
                # We need to go through those sub comments
                getComments(comment.comments)
                continue
            if comment.author is None or comment.author.name == '[deleted]':
                # Skip deleted users or removed comments
                continue
            author = comment.author.name if comment.author else '[deleted]'
            text = comment.body
            date = comment.created_utc
            score = comment.score
            data.append([author, text, date, score, 'paleo'])
    except:
        print("")

getComments(comments)

# Create a pandas DataFrame from the data
df10 = pd.DataFrame(data, columns=['Author', 'Text', 'Date', 'Score', 'Keyword'])

# Write the DataFrame to a CSV file
df10.to_csv('reddit_data_paleo2.csv', index=False)

from praw.models import MoreComments
post_id = '1bsqdu4'
num_comments = 100

post = reddit.submission(id=post_id)

comments = post.comments[:num_comments]

data = []

def getComments(comments):
    try:
        for comment in comments:
            if isinstance(comment,MoreComments):
                # This is a comment that has more comments inside it
                # We need to go through those sub comments
                getComments(comment.comments)
                continue
            if comment.author is None or comment.author.name == '[deleted]':
                # Skip deleted users or removed comments
                continue
            author = comment.author.name if comment.author else '[deleted]'
            text = comment.body
            date = comment.created_utc
            score = comment.score
            data.append([author, text, date, score, 'paleo'])
    except:
        print("")

getComments(comments)

# Create a pandas DataFrame from the data
df11 = pd.DataFrame(data, columns=['Author', 'Text', 'Date', 'Score', 'Keyword'])

# Write the DataFrame to a CSV file
df11.to_csv('reddit_data_paleo3.csv', index=False)

df_paleo = pd.concat([df9, df10, df11], ignore_index=True)
df_paleo.to_csv('reddit_data_paleo.csv', index=False)

"""FINAL"""

df_final = pd.concat([df_keto, df_vegan, df_paleo, balanced_df], ignore_index=True)
df_final.to_csv('reddit_data_final.csv', index=False)